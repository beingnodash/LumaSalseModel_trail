"""
å¢å¼ºç‰ˆæ•æ„Ÿæ€§åˆ†æå·¥å…·
Enhanced Sensitivity Analysis Tools

ä¸“ä¸ºç®€åŒ–ç‰ˆ7å¤§ç±»å‚æ•°ç»“æ„è®¾è®¡çš„æ•æ„Ÿæ€§åˆ†æåŠŸèƒ½ï¼š
1. æ”¯æŒ7å¤§ç±»å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æ
2. å¤šå‚æ•°åŒæ—¶åˆ†æ
3. ç›¸å…³æ€§åˆ†æ
4. å‚æ•°å½±å“æ’åº
5. ä¸šåŠ¡ç­–ç•¥å»ºè®®
"""

import pandas as pd
import numpy as np
import streamlit as st
import copy
from typing import Dict, List, Tuple, Any, Optional
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

class EnhancedSensitivityAnalyzer:
    """å¢å¼ºç‰ˆæ•æ„Ÿæ€§åˆ†æå™¨"""
    
    def __init__(self, base_params: Dict[str, Any]):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            base_params: åŸºç¡€å‚æ•°é…ç½®
        """
        self.base_params = copy.deepcopy(base_params)
        self.results = None
        self.parameter_definitions = self._get_parameter_definitions()
    
    def _get_parameter_definitions(self) -> Dict[str, Dict]:
        """è·å–å‚æ•°å®šä¹‰å’Œæµ‹è¯•èŒƒå›´"""
        return {
            # åŸºç¡€å‚æ•°
            'total_half_years': {
                'category': 'åŸºç¡€å‚æ•°',
                'name': 'æ¨¡æ‹Ÿå‘¨æœŸæ•°',
                'min': 4, 'max': 16, 'steps': 7,
                'format': '%.0f', 'unit': 'ä¸ªåŠå¹´',
                'description': 'æ¨¡æ‹Ÿçš„åŠå¹´å‘¨æœŸæ•°é‡'
            },
            
            # ä»·æ ¼å‚æ•° - å­¦ç”Ÿç«¯
            'price_per_use': {
                'category': 'ä»·æ ¼å‚æ•°',
                'name': 'å­¦ç”Ÿå•æ¬¡ä»˜è´¹ä»·æ ¼',
                'min': 5.0, 'max': 20.0, 'steps': 8,
                'format': '%.1f', 'unit': 'å…ƒ',
                'description': 'å­¦ç”ŸæŒ‰æ¬¡ä½¿ç”¨åŠŸèƒ½çš„ä»·æ ¼'
            },
            'price_1year_member': {
                'category': 'ä»·æ ¼å‚æ•°',
                'name': 'å­¦ç”Ÿ1å¹´è®¢é˜…ä»·æ ¼',
                'min': 100.0, 'max': 300.0, 'steps': 9,
                'format': '%.0f', 'unit': 'å…ƒ',
                'description': 'å­¦ç”Ÿ1å¹´è®¢é˜…ä¼šå‘˜ä»·æ ¼'
            },
            'price_3year_member': {
                'category': 'ä»·æ ¼å‚æ•°',
                'name': 'å­¦ç”Ÿ3å¹´è®¢é˜…ä»·æ ¼',
                'min': 300.0, 'max': 600.0, 'steps': 7,
                'format': '%.0f', 'unit': 'å…ƒ',
                'description': 'å­¦ç”Ÿ3å¹´è®¢é˜…ä¼šå‘˜ä»·æ ¼'
            },
            
            # ä»·æ ¼å‚æ•° - é«˜æ ¡ç«¯
            'mode_a_price': {
                'category': 'ä»·æ ¼å‚æ•°',
                'name': 'æ¨¡å¼Aé«˜æ ¡å®šä»·',
                'min': 400000.0, 'max': 1000000.0, 'steps': 7,
                'format': '%.0f', 'unit': 'å…ƒ',
                'description': 'æ¨¡å¼Aé«˜æ ¡3å¹´æœåŠ¡è´¹ç”¨'
            },
            'mode_b_price': {
                'category': 'ä»·æ ¼å‚æ•°',
                'name': 'æ¨¡å¼Bé«˜æ ¡å®šä»·',
                'min': 200000.0, 'max': 600000.0, 'steps': 9,
                'format': '%.0f', 'unit': 'å…ƒ',
                'description': 'æ¨¡å¼Bé«˜æ ¡3å¹´æœåŠ¡è´¹ç”¨'
            },
            
            # å¸‚åœºè§„æ¨¡
            'new_clients_per_half_year': {
                'category': 'å¸‚åœºè§„æ¨¡',
                'name': 'æ¯åŠå¹´æ–°å®¢æˆ·æ•°',
                'min': 2, 'max': 15, 'steps': 8,
                'format': '%.0f', 'unit': 'æ‰€',
                'description': 'æ¯åŠå¹´æ–°è·å–çš„é«˜æ ¡å®¢æˆ·æ•°'
            },
            'avg_students_per_uni': {
                'category': 'å¸‚åœºè§„æ¨¡',
                'name': 'å¹³å‡å­¦æ ¡è§„æ¨¡',
                'min': 5000, 'max': 20000, 'steps': 8,
                'format': '%.0f', 'unit': 'äºº',
                'description': 'æ¯æ‰€é«˜æ ¡çš„å¹³å‡å­¦ç”Ÿæ•°é‡'
            },
            
            # å¸‚åœºåˆ†å¸ƒ
            'mode_a_ratio': {
                'category': 'å¸‚åœºåˆ†å¸ƒ',
                'name': 'æ¨¡å¼Aå æ¯”',
                'min': 0.1, 'max': 0.6, 'steps': 6,
                'format': '%.1%', 'unit': '',
                'description': 'é€‰æ‹©æ¨¡å¼Açš„é«˜æ ¡æ¯”ä¾‹'
            },
            'mode_b_ratio': {
                'category': 'å¸‚åœºåˆ†å¸ƒ',
                'name': 'æ¨¡å¼Bå æ¯”',
                'min': 0.1, 'max': 0.6, 'steps': 6,
                'format': '%.1%', 'unit': '',
                'description': 'é€‰æ‹©æ¨¡å¼Bçš„é«˜æ ¡æ¯”ä¾‹'
            },
            'student_paid_conversion_rate_bc': {
                'category': 'å¸‚åœºåˆ†å¸ƒ',
                'name': 'B/Cå­¦ç”Ÿä»˜è´¹è½¬åŒ–ç‡',
                'min': 0.02, 'max': 0.25, 'steps': 8,
                'format': '%.1%', 'unit': '',
                'description': 'B/Cæ¨¡å¼ä¸‹å­¦ç”Ÿä»˜è´¹è½¬åŒ–ç‡'
            },
            
            # å­¦ç”Ÿå¸‚åœºç»†åˆ†
            'per_use_ratio': {
                'category': 'å­¦ç”Ÿå¸‚åœºç»†åˆ†',
                'name': 'æŒ‰æ¬¡ä»˜è´¹ç”¨æˆ·å æ¯”',
                'min': 0.2, 'max': 0.8, 'steps': 7,
                'format': '%.1%', 'unit': '',
                'description': 'é€‰æ‹©æŒ‰æ¬¡ä»˜è´¹çš„å­¦ç”Ÿæ¯”ä¾‹'
            },
            
            # ç»­è´¹ç‡å‚æ•°
            'university_3year_renewal': {
                'category': 'ç»­è´¹ç‡å‚æ•°',
                'name': 'é«˜æ ¡3å¹´ç»­çº¦ç‡',
                'min': 0.5, 'max': 0.95, 'steps': 10,
                'format': '%.1%', 'unit': '',
                'description': 'é«˜æ ¡3å¹´æœåŠ¡æœŸåçš„ç»­çº¦ç‡'
            },
            'student_per_use_repurchase': {
                'category': 'ç»­è´¹ç‡å‚æ•°',
                'name': 'å­¦ç”ŸæŒ‰æ¬¡ä»˜è´¹å¤è´­ç‡',
                'min': 0.4, 'max': 0.9, 'steps': 6,
                'format': '%.1%', 'unit': '',
                'description': 'å­¦ç”ŸæŒ‰æ¬¡ä»˜è´¹çš„å¤è´­æ¦‚ç‡'
            },
            'student_subscription_renewal': {
                'category': 'ç»­è´¹ç‡å‚æ•°',
                'name': 'å­¦ç”Ÿè®¢é˜…ç»­è´¹ç‡',
                'min': 0.5, 'max': 0.9, 'steps': 9,
                'format': '%.1%', 'unit': '',
                'description': 'å­¦ç”Ÿè®¢é˜…åˆ°æœŸåçš„ç»­è´¹ç‡'
            },
            
            # åˆ†æˆæ¯”ä¾‹
            'luma_share_from_student': {
                'category': 'åˆ†æˆæ¯”ä¾‹',
                'name': 'Lumaå­¦ç”Ÿåˆ†æˆæ¯”ä¾‹',
                'min': 0.2, 'max': 0.7, 'steps': 6,
                'format': '%.1%', 'unit': '',
                'description': 'B/Cæ¨¡å¼ä¸‹Lumaçš„åˆ†æˆæ¯”ä¾‹'
            }
        }
    
    def get_parameter_path(self, param_key: str) -> List[str]:
        """è·å–å‚æ•°åœ¨åµŒå¥—å­—å…¸ä¸­çš„è·¯å¾„"""
        path_mapping = {
            # åŸºç¡€å‚æ•°
            'total_half_years': ['total_half_years'],
            
            # å­¦ç”Ÿä»·æ ¼å‚æ•°
            'price_per_use': ['student_prices', 'price_per_use'],
            'price_1year_member': ['student_prices', 'price_1year_member'],
            'price_3year_member': ['student_prices', 'price_3year_member'],
            'price_5year_member': ['student_prices', 'price_5year_member'],
            
            # é«˜æ ¡ä»·æ ¼å‚æ•°
            'mode_a_price': ['university_prices', 'mode_a_price'],
            'mode_b_price': ['university_prices', 'mode_b_price'],
            
            # å¸‚åœºè§„æ¨¡
            'new_clients_per_half_year': ['market_scale', 'new_clients_per_half_year'],
            'avg_students_per_uni': ['market_scale', 'avg_students_per_uni'],
            
            # å¸‚åœºåˆ†å¸ƒ
            'mode_a_ratio': ['market_distribution', 'mode_a_ratio'],
            'mode_b_ratio': ['market_distribution', 'mode_b_ratio'],
            'mode_c_ratio': ['market_distribution', 'mode_c_ratio'],
            'student_paid_conversion_rate_bc': ['market_distribution', 'student_paid_conversion_rate_bc'],
            
            # å­¦ç”Ÿå¸‚åœºç»†åˆ†
            'per_use_ratio': ['student_segmentation', 'per_use_ratio'],
            
            # ç»­è´¹ç‡å‚æ•°
            'university_3year_renewal': ['renewal_rates', 'university_3year_renewal'],
            'student_per_use_repurchase': ['renewal_rates', 'student_per_use_repurchase'],
            'student_subscription_renewal': ['renewal_rates', 'student_subscription_renewal'],
            
            # åˆ†æˆæ¯”ä¾‹
            'luma_share_from_student': ['revenue_sharing', 'luma_share_from_student']
        }
        return path_mapping.get(param_key, [param_key])
    
    def set_nested_value(self, params: Dict, path: List[str], value: Any) -> None:
        """åœ¨åµŒå¥—å­—å…¸ä¸­è®¾ç½®å€¼"""
        current = params
        for key in path[:-1]:
            if key not in current:
                current[key] = {}
            current = current[key]
        current[path[-1]] = value
    
    def get_nested_value(self, params: Dict, path: List[str]) -> Any:
        """ä»åµŒå¥—å­—å…¸ä¸­è·å–å€¼"""
        current = params
        for key in path:
            current = current[key]
        return current
    
    def generate_test_values(self, param_key: str, custom_range: Optional[Tuple[float, float, int]] = None) -> List[float]:
        """ç”Ÿæˆå‚æ•°æµ‹è¯•å€¼"""
        if param_key not in self.parameter_definitions:
            raise ValueError(f"æœªçŸ¥å‚æ•°: {param_key}")
        
        param_def = self.parameter_definitions[param_key]
        
        if custom_range:
            min_val, max_val, steps = custom_range
        else:
            min_val = param_def['min']
            max_val = param_def['max']
            steps = param_def['steps']
        
        test_values = np.linspace(min_val, max_val, steps)
        return test_values.tolist()
    
    def run_single_parameter_analysis(self, param_key: str, model_class, 
                                    test_values: Optional[List[float]] = None,
                                    output_metrics: Optional[List[str]] = None) -> pd.DataFrame:
        """
        è¿è¡Œå•å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        
        Args:
            param_key: è¦åˆ†æçš„å‚æ•°é”®
            model_class: æ¨¡å‹ç±»
            test_values: æµ‹è¯•å€¼åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤èŒƒå›´
            output_metrics: è¦è·Ÿè¸ªçš„è¾“å‡ºæŒ‡æ ‡
            
        Returns:
            åŒ…å«åˆ†æç»“æœçš„DataFrame
        """
        if test_values is None:
            test_values = self.generate_test_values(param_key)
        
        if output_metrics is None:
            output_metrics = [
                'luma_revenue_total', 'uni_revenue_total', 'student_revenue_total',
                'active_universities', 'total_paying_students'
            ]
        
        results = []
        param_path = self.get_parameter_path(param_key)
        
        for i, test_value in enumerate(test_values):
            # åˆ›å»ºå‚æ•°å‰¯æœ¬
            test_params = copy.deepcopy(self.base_params)
            
            # è®¾ç½®æµ‹è¯•å€¼
            self.set_nested_value(test_params, param_path, test_value)
            
            # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœä¿®æ”¹äº†æ¨¡å¼Aæˆ–Bçš„å æ¯”ï¼Œéœ€è¦è°ƒæ•´æ¨¡å¼C
            if param_key in ['mode_a_ratio', 'mode_b_ratio']:
                self._adjust_mode_ratios(test_params, param_key, test_value)
            
            try:
                # è¿è¡Œæ¨¡å‹
                model = model_class(test_params)
                results_df = model.run_model()
                
                # æå–æŒ‡æ ‡
                result_row = {param_key: test_value}
                
                for metric in output_metrics:
                    if metric in results_df.columns:
                        # è®¡ç®—æ€»å’Œï¼ˆå¯¹äºæ”¶å…¥ç±»æŒ‡æ ‡ï¼‰æˆ–æœ€å¤§å€¼ï¼ˆå¯¹äºæ•°é‡ç±»æŒ‡æ ‡ï¼‰
                        if 'revenue' in metric or 'income' in metric:
                            result_row[metric] = results_df[metric].sum()
                        else:
                            result_row[metric] = results_df[metric].max()
                    else:
                        result_row[metric] = 0
                
                # æ·»åŠ ä¸šåŠ¡æ‘˜è¦æŒ‡æ ‡
                summary = model.get_business_summary()
                result_row['avg_revenue_per_period'] = summary['avg_luma_revenue_per_period']
                result_row['revenue_growth_rate'] = summary['revenue_growth_rate']
                result_row['peak_active_universities'] = summary['peak_active_universities']
                result_row['peak_paying_students'] = summary['peak_paying_students']
                
                results.append(result_row)
                
            except Exception as e:
                st.warning(f"å‚æ•°å€¼ {test_value} è¿è¡Œå¤±è´¥: {str(e)}")
                continue
        
        return pd.DataFrame(results)
    
    def _adjust_mode_ratios(self, params: Dict, changed_param: str, new_value: float) -> None:
        """è°ƒæ•´å•†ä¸šæ¨¡å¼æ¯”ä¾‹ï¼Œç¡®ä¿æ€»å’Œä¸º1"""
        dist = params['market_distribution']
        
        # è®¾ç½®æ–°å€¼
        dist[changed_param] = new_value
        
        if changed_param == 'mode_a_ratio':
            # æŒ‰æ¯”ä¾‹è°ƒæ•´Bå’ŒC
            remaining = 1.0 - new_value
            current_bc_sum = dist['mode_b_ratio'] + dist['mode_c_ratio']
            if current_bc_sum > 0:
                ratio = remaining / current_bc_sum
                dist['mode_b_ratio'] *= ratio
                dist['mode_c_ratio'] *= ratio
            else:
                dist['mode_b_ratio'] = remaining / 2
                dist['mode_c_ratio'] = remaining / 2
        
        elif changed_param == 'mode_b_ratio':
            # æŒ‰æ¯”ä¾‹è°ƒæ•´Aå’ŒC
            remaining = 1.0 - new_value
            current_ac_sum = dist['mode_a_ratio'] + dist['mode_c_ratio']
            if current_ac_sum > 0:
                ratio = remaining / current_ac_sum
                dist['mode_a_ratio'] *= ratio
                dist['mode_c_ratio'] *= ratio
            else:
                dist['mode_a_ratio'] = remaining / 2
                dist['mode_c_ratio'] = remaining / 2
        
        elif changed_param == 'mode_c_ratio':
            # æŒ‰æ¯”ä¾‹è°ƒæ•´Aå’ŒB
            remaining = 1.0 - new_value
            current_ab_sum = dist['mode_a_ratio'] + dist['mode_b_ratio']
            if current_ab_sum > 0:
                ratio = remaining / current_ab_sum
                dist['mode_a_ratio'] *= ratio
                dist['mode_b_ratio'] *= ratio
            else:
                dist['mode_a_ratio'] = remaining / 2
                dist['mode_b_ratio'] = remaining / 2
    
    def run_multi_parameter_analysis(self, param_configs: Dict[str, Dict], model_class,
                                   output_metrics: Optional[List[str]] = None) -> Dict[str, pd.DataFrame]:
        """
        è¿è¡Œå¤šå‚æ•°æ•æ„Ÿæ€§åˆ†æ
        
        Args:
            param_configs: å‚æ•°é…ç½®å­—å…¸ï¼Œæ ¼å¼ä¸º {param_key: {'values': [...]}}
            model_class: æ¨¡å‹ç±»
            output_metrics: è¦è·Ÿè¸ªçš„è¾“å‡ºæŒ‡æ ‡
            
        Returns:
            åŒ…å«å„å‚æ•°åˆ†æç»“æœçš„å­—å…¸
        """
        results = {}
        
        for param_key, config in param_configs.items():
            st.write(f"æ­£åœ¨åˆ†æå‚æ•°: {self.parameter_definitions[param_key]['name']}")
            
            test_values = config.get('values')
            if test_values is None:
                test_values = self.generate_test_values(param_key)
            
            result_df = self.run_single_parameter_analysis(
                param_key, model_class, test_values, output_metrics
            )
            results[param_key] = result_df
        
        return results
    
    def calculate_parameter_importance(self, results: Dict[str, pd.DataFrame], 
                                     target_metric: str = 'luma_revenue_total') -> pd.DataFrame:
        """
        è®¡ç®—å‚æ•°é‡è¦æ€§æ’åº
        
        Args:
            results: å¤šå‚æ•°åˆ†æç»“æœ
            target_metric: ç›®æ ‡æŒ‡æ ‡
            
        Returns:
            å‚æ•°é‡è¦æ€§æ’åºDataFrame
        """
        importance_data = []
        
        for param_key, result_df in results.items():
            if target_metric in result_df.columns and len(result_df) > 1:
                # è®¡ç®—å˜å¼‚ç³»æ•°ï¼ˆæ ‡å‡†å·®/å‡å€¼ï¼‰
                values = result_df[target_metric]
                mean_val = values.mean()
                std_val = values.std()
                cv = std_val / mean_val if mean_val > 0 else 0
                
                # è®¡ç®—å˜åŒ–å¹…åº¦ï¼ˆæœ€å¤§å€¼-æœ€å°å€¼ï¼‰/æœ€å°å€¼
                min_val = values.min()
                max_val = values.max()
                change_rate = (max_val - min_val) / min_val if min_val > 0 else 0
                
                # è®¡ç®—ç›¸å…³ç³»æ•°
                param_values = result_df[param_key]
                correlation = np.corrcoef(param_values, values)[0, 1] if len(param_values) > 1 else 0
                
                param_def = self.parameter_definitions[param_key]
                
                importance_data.append({
                    'å‚æ•°': param_def['name'],
                    'å‚æ•°ç±»åˆ«': param_def['category'],
                    'å˜å¼‚ç³»æ•°': cv,
                    'å˜åŒ–å¹…åº¦': change_rate,
                    'ç›¸å…³ç³»æ•°': correlation,
                    'é‡è¦æ€§å¾—åˆ†': cv * abs(correlation),  # ç»¼åˆå¾—åˆ†
                    'æœ€å°å€¼': min_val,
                    'æœ€å¤§å€¼': max_val,
                    'å¹³å‡å€¼': mean_val
                })
        
        importance_df = pd.DataFrame(importance_data)
        importance_df = importance_df.sort_values('é‡è¦æ€§å¾—åˆ†', ascending=False)
        
        return importance_df
    
    def generate_business_insights(self, importance_df: pd.DataFrame, 
                                 target_metric: str = 'luma_revenue_total') -> List[str]:
        """
        ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿå»ºè®®
        
        Args:
            importance_df: å‚æ•°é‡è¦æ€§åˆ†æç»“æœ
            target_metric: ç›®æ ‡æŒ‡æ ‡
            
        Returns:
            ä¸šåŠ¡å»ºè®®åˆ—è¡¨
        """
        insights = []
        
        if len(importance_df) == 0:
            return ["æš‚æ— è¶³å¤Ÿæ•°æ®ç”Ÿæˆä¸šåŠ¡æ´å¯Ÿ"]
        
        # è¯†åˆ«æœ€é‡è¦çš„å‚æ•°
        top_params = importance_df.head(3)
        
        insights.append(f"ğŸ“Š **å…³é”®å‘ç°**: å½±å“{target_metric}æœ€é‡è¦çš„3ä¸ªå‚æ•°ï¼š")
        for i, row in top_params.iterrows():
            change_pct = row['å˜åŒ–å¹…åº¦'] * 100
            correlation = row['ç›¸å…³ç³»æ•°']
            direction = "æ­£å‘" if correlation > 0 else "è´Ÿå‘"
            insights.append(f"   â€¢ **{row['å‚æ•°']}** ({row['å‚æ•°ç±»åˆ«']}): {direction}å½±å“ï¼Œå˜åŒ–å¹…åº¦{change_pct:.1f}%")
        
        # æŒ‰ç±»åˆ«åˆ†æ
        category_importance = importance_df.groupby('å‚æ•°ç±»åˆ«')['é‡è¦æ€§å¾—åˆ†'].sum().sort_values(ascending=False)
        insights.append(f"\nğŸ¯ **å‚æ•°ç±»åˆ«é‡è¦æ€§æ’åº**:")
        for category, score in category_importance.head(3).items():
            insights.append(f"   â€¢ {category}: é‡è¦æ€§å¾—åˆ† {score:.3f}")
        
        # ç”Ÿæˆå…·ä½“å»ºè®®
        insights.append(f"\nğŸ’¡ **ä¼˜åŒ–å»ºè®®**:")
        
        top_param = importance_df.iloc[0]
        if top_param['ç›¸å…³ç³»æ•°'] > 0:
            insights.append(f"   â€¢ é‡ç‚¹å…³æ³¨æå‡ã€Œ{top_param['å‚æ•°']}ã€ï¼Œè¯¥å‚æ•°ä¸æ”¶å…¥å‘ˆæ­£ç›¸å…³")
        else:
            insights.append(f"   â€¢ æ³¨æ„æ§åˆ¶ã€Œ{top_param['å‚æ•°']}ã€ï¼Œè¯¥å‚æ•°ä¸æ”¶å…¥å‘ˆè´Ÿç›¸å…³")
        
        # è¯†åˆ«é«˜å˜å¼‚å‚æ•°
        high_variation = importance_df[importance_df['å˜åŒ–å¹…åº¦'] > 0.5]
        if len(high_variation) > 0:
            insights.append("   â€¢ ä»¥ä¸‹å‚æ•°å˜åŒ–å¯¹ç»“æœå½±å“è¾ƒå¤§ï¼Œå»ºè®®åŠ å¼ºç›‘æ§:")
            for _, row in high_variation.head(2).iterrows():
                insights.append(f"     - {row['å‚æ•°']}: å˜åŒ–å¹…åº¦{row['å˜åŒ–å¹…åº¦']*100:.1f}%")
        
        return insights